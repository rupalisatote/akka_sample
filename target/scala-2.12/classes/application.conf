akka {
  loggers          = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter   = "akka.event.slf4j.Slf4jLoggingFilter"
  loglevel         = "debug"
  log-dead-letters = "off"
  stdout-loglevel  = "info"

  coordinated-shutdown {
    default-phase-timeout = 10 seconds
    exit-jvm = on
  }

   # Akka Bootstrap Discovery settings
    discovery {
      # Kubernetes API is used as discovery method
      # https://developer.lightbend.com/docs/akka-management/current/discovery/index.html#discovery-method-kubernetes-api
      method = kubernetes-api

      kubernetes-api {
        # Namespace to query for pods
        # The lookup needs to know which namespace to look in.
        # By default, this will be detected by reading the namespace from the service account secret,
        # in /var/run/secrets/kubernetes.io/serviceaccount/namespace
        # Namespace can be overriden with `pod-namespace` key.
        pod-namespace = "demo-1"

        # Selector value to query pod API with.
        # `%s` will be replaced with the configured effective name, which defaults to the actor system name
        # Default: "app=%s"
        pod-label-selector = "app=k8s-viz"

        # The name of the akka management port
        # Default: "management"
        pod-port-name = "management"
      }
    }

  management {

   #health-checks {
       #readiness-checks {
         # Default health check for cluster. Overwrite the setting to replace it with
         # your implementation or set it to "" (empty string) to disable this check.
         #cluster-membership = "akka.management.cluster.scaladsl.ClusterMembershipCheck"
       #}
     #}

    http {
          hostname = "127.0.0.1"
          hostname = ${?HOSTNAME}
          bind-hostname = "0.0.0.0"
          port = 8558
          bind-port = 8558
    }

    cluster.bootstrap {

        contact-point-discovery {

            service-name = "k8s-viz"

            discovery-method = kubernetes-api

             # The smallest number of contact points that need to be discovered before the bootstrap process can start.
            # For optimal safety during cluster formation, you may want to set these value to the number of initial
            # nodes that you know will participate in the cluster (e.g. the value of `spec.replicas` as set in your kubernetes config.
            required-contact-point-nr = 2

            # Amount of time for which a discovery observation must remain "stable"
            # (i.e. not change list of discovered contact-points) before a join decision can be made.
            # This is done to decrease the likelyhood of performing decisions on fluctuating observations.
            #
            # This timeout represents a tradeoff between safety and quickness of forming a new cluster.
            stable-margin = 5 seconds
        }

    }
  }

  contrib {
    persistence {
      mongodb.mongo.mongouri = "mongodb://host.docker.internal:27017"
      mongodb.mongo.database = "k8s-db"
      mongodb.mongo.journal-collection = "k8s_journal"
      mongodb.mongo.journal-index = "k8s_journal_index"
      mongodb.mongo.snaps-collection = "k8s_persistent_snapshots"
      mongodb.mongo.snaps-index = "k8s_snaps_index"
      mongodb.mongo.journal-write-concern = "Acknowledged"
    }
  }

    actor {
      provider = cluster
    }

    remote {
      log-remote-lifecycle-events = on
      netty.tcp {
        hostname = "127.0.0.1"
        hostname = ${?HOSTNAME}
        port = 2552
        port = ${?PORT}
        bind-hostname = "0.0.0.0"
        bind-port = 2552
      }
    }

    #remote {
      #netty.tcp {
        #hostname = "127.0.0.1"
        #port = 0
      #}

      #artery {
        # change this to enabled=on to use Artery instead of netty
        # see https://doc.akka.io/docs/akka/current/remoting-artery.html
        #enabled = off
        #transport = tcp
        #canonical.hostname = "127.0.0.1"
        #canonical.port = 0
      #}
    #}

    persistence {
      journal {
        plugin = "akka-contrib-mongodb-persistence-journal"
      }
      snapshot-store {
        plugin = "akka-contrib-mongodb-persistence-snapshot"
      }
    }

    cluster {

      roles = ["backend"]
      roles = [${?AKKA_ROLES}]
      #seed-nodes = ["akka.tcp://K8SNode@127.0.0.1:2551", "akka.tcp://K8SNode@127.0.0.1:2552"]

      # auto downing is NOT safe for production deployments.
      # you may want to use it during development, read more about it in the docs.
      #auto-down-unreachable-after = 60s

      #shutdown-after-unsuccessful-join-seed-nodes = 60s

      sharding {
        state-store-mode = persistence
      }
    }

  }

# Enable Distributed Pubsub extension.
akka.extensions=["akka.cluster.pubsub.DistributedPubSub"]

# Sigar native library extract location during tests.
# Note: use per-jvm-instance folder when running multiple jvm on one host.
#akka.cluster.metrics.native-library-extract-folder=${user.dir}/target/native


sse {
  address             = "0.0.0.0"
  port                = 8000
  heartbeat           = 10 s
  bufferSize          = 100
}

sample {
  cluster {
    k8s {
      sharding {
        max-shards = 15
        topic = "k8s"
        passivate-after = 120.seconds,
        max-inbox-size = 50
      }
      ws {
        topic = "k8s"
        http-service-name = "event-publisher"
        http-port = 9000
        http-port = ${?WS_HTTP_PORT}
      }
      gossip {
        topic = "k8s"
        actor-name = "membership-listener"
      }
      cmd {
        actor-name = "command-actor"
        call-every = 1.seconds
        initial-delay = 3.seconds
      }
      routees {
        topic = "k8s"
        actor-name = "routee"
        max-instances = 100
        max-instances-per-node = 5
      }

      provider-hub {
        topic = "k8s"
        max-processing-delay = 2.seconds
        singleton-name = "provider-hub"
        singleton-manager-name = "singleton"
        max-hand-over-retries = 10
        max-take-over-retries = 5
        retry-interval = 1.second
        max-inbox-size = 50
      }
    }
  }
}